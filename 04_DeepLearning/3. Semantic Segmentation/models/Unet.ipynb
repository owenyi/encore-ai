{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Unet.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"mDq9jdVQJIXB"},"source":["이 코드는 조금 쉽게 작성한 UNet 모델이다. 더 어렵게 작성할 수도 있다.\n","하지만 공통적인 부분은 큰 틀에서 거의 동일하다.\n","\n","큰 틀을 보면,\n","1. 메인 모델 클래스 정의\n","   class UNET(nn.Module):\n","2. 메인 모델 클래스에서 사용할 서브모듈을 정의\n","   class DoubleConv(nn.Module): --> Conv2d + BatchNorm2d + ReLU 이게 2번 반복\n","   class Down(nn.Module): --> stride=2를 사용해서 사이즈를 정확히 반으로 줄임\n","   class Up(nn.Module): --> stride=1이 지정됨. 사이즈 2배로 늘림...interpolation방법 사용...concat...dim=1\n","                        100, 3, 28, 28...채널을 중심으로 concat\n","\n","여기서 한 가지!!\n","자주 사용하는 코드들은 당연히 모듈화 시켜놓고\n","필요할 때 함수를 호출해서 재사용성을 높인다.\n","모델 클래스를 작성할 때\n","딱 이 2가지 패턴으로 작성한다.\n","1. 지금처럼 코드 안에 서브 모듈을 정의해서 바로 사용하는 경우\n","2. module.py로 빼놓고 거기서 뽑아쓰는 방법"]},{"cell_type":"code","metadata":{"id":"sCN_iC0cHZmg"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import pdb\n","\n","class DoubleConv(nn.Module):\n","    def __init__(self, in_channels, out_channels, stride=1):\n","        super().__init__()\n","        assert stride in [1, 2]\n","        self.double_conv = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True))\n","\n","    def forward(self, x):\n","        return self.double_conv(x)\n","\n","\n","class Down(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.conv = nn.Sequential(\n","            DoubleConv(in_channels, out_channels, stride=2))\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        return x\n","\n","\n","class Up(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.conv = DoubleConv(in_channels, out_channels)\n","\n","    def forward(self, x1, x2):\n","        h, w = x1.size()[2:]\n","        x1 = F.interpolate(x1, (h*2,w*2))\n","        x = torch.cat([x2, x1], dim=1)\n","        return self.conv(x)\n","\n","\n","class UNet(nn.Module):\n","    def __init__(self, classes, model):\n","        super(UNet, self).__init__()\n","        if model == 'unet32': # 가벼운 모델....성능은 다소 떨어져도 속도가 빠름\n","            base_channels=32\n","        elif model == 'unet64':\n","            base_channels=64\n","        elif model == 'unet128': # 무거운 모델...위와 반대...성능이 어느정도 보장\n","            base_channels=128\n","        else: # 이 밖의 채널이 들어오면 에러\n","            raise ValueError(f'{model} is not supported model')\n","\n","        self.inc   = DoubleConv(3, base_channels) # Assume input has 3 channels\n","        self.down1 = Down(base_channels, base_channels*2)\n","        self.down2 = Down(base_channels*2, base_channels*4)\n","        self.down3 = Down(base_channels*4, base_channels*8)\n","        self.down4 = Down(base_channels*8, base_channels*8)\n","        self.up1   = Up(base_channels*16, base_channels*4)\n","        self.up2   = Up(base_channels*8, base_channels*2)\n","        self.up3   = Up(base_channels*4, base_channels)\n","        self.up4   = Up(base_channels*2, base_channels)\n","        self.outc  = nn.Conv2d(base_channels, classes, kernel_size=1)\n","\n","    def forward(self, x):\n","        x1 = self.inc(x)\n","        x2 = self.down1(x1)\n","        x3 = self.down2(x2)\n","        x4 = self.down3(x3)\n","        x5 = self.down4(x4)\n","        x = self.up1(x5, x4)\n","        x = self.up2(x, x3)\n","        x = self.up3(x, x2)\n","        x = self.up4(x, x1)\n","        x = self.outc(x)\n","        return x\n","\n","\n","if __name__ == \"__main__\":\n","    import pdb\n","\n","    model = UNet(2, 'unet128').cuda()\n","    x = torch.rand(4,3,256,256).cuda()\n","    y = model(x)\n","    print(y.size())"],"execution_count":null,"outputs":[]}]}