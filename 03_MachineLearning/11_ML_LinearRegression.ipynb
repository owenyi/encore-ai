{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측 함수\n",
    "\n",
    "$$\n",
    "Y = Wx + b\n",
    "$$\n",
    "\n",
    "x는 특성, y는 예측 값이다. \n",
    "W는 기울기, b는 y절편을 뜻하지만 W는 가중치(weight), b는 offset으로 부를 수도 있다.\n",
    "선형 회귀에서는 여러 샘플의 특성 값과 예측 값을 활용해 가장 적절한 w와 b를 구하는 것이 목적이다.\n",
    "### 평균 제곱 오차 (Mean Square Error)\n",
    "선형 회귀에서는 Coast 함수(또는 비용 함수)로 평균 제곱 오차를 사용한다. \n",
    "여기서 Coast 함수란 샘플 데이터와 타깃과의 유사도를 의미하며 Coast 함수가 최소가 되도록 \n",
    "파라미터를 학습시킨다. \n",
    "$$\n",
    "   \\frac{1}{n}\\sum(pred_i - y_i)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([1., 2., 3., 4., 5., 6.])\n",
    "Y = np.array([9., 16., 23., 30., 37., 44.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W, B값은 0으로 초기화 되어져 있습니다.\n",
    "W = 0.0\n",
    "b = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_data = len(X)\n",
    "n_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5000 # 전체 데이터 셋에 대해 한 번 학습을 하는 사이클을 의미한다.\n",
    "learning_rate = 0.01 #학습속도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \n",
    "    아랫 부분은 머신러닝 알고리즘을 활용하여 \n",
    "    전체 EPOCH 을 돌면서 가장 Cost가 낮은 W,B값을 찾아서 예측값을 출력해보세요\n",
    "    이때 위에 있는 MSE 함수 원리는 그대로 적용한 코드를 만들어서 손실 부분을 \n",
    "    계산하시기 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch (         0/      5000) cost:845.166667, W :  1.131667,b:  0.265000\n",
      "Epoch (       100/      5000) cost:  0.015993, W :  7.067217,b:  1.712232\n",
      "Epoch (       200/      5000) cost:  0.011099, W :  7.055996,b:  1.760269\n",
      "Epoch (       300/      5000) cost:  0.007703, W :  7.046649,b:  1.800288\n",
      "Epoch (       400/      5000) cost:  0.005346, W :  7.038862,b:  1.833626\n",
      "Epoch (       500/      5000) cost:  0.003710, W :  7.032374,b:  1.861399\n",
      "Epoch (       600/      5000) cost:  0.002575, W :  7.026970,b:  1.884536\n",
      "Epoch (       700/      5000) cost:  0.001787, W :  7.022468,b:  1.903810\n",
      "Epoch (       800/      5000) cost:  0.001240, W :  7.018717,b:  1.919867\n",
      "Epoch (       900/      5000) cost:  0.000861, W :  7.015593,b:  1.933244\n",
      "Epoch (      1000/      5000) cost:  0.000597, W :  7.012990,b:  1.944387\n",
      "Epoch (      1100/      5000) cost:  0.000415, W :  7.010822,b:  1.953671\n",
      "Epoch (      1200/      5000) cost:  0.000288, W :  7.009015,b:  1.961405\n",
      "Epoch (      1300/      5000) cost:  0.000200, W :  7.007510,b:  1.967847\n",
      "Epoch (      1400/      5000) cost:  0.000139, W :  7.006256,b:  1.973215\n",
      "Epoch (      1500/      5000) cost:  0.000096, W :  7.005212,b:  1.977686\n",
      "Epoch (      1600/      5000) cost:  0.000067, W :  7.004342,b:  1.981411\n",
      "Epoch (      1700/      5000) cost:  0.000046, W :  7.003617,b:  1.984514\n",
      "Epoch (      1800/      5000) cost:  0.000032, W :  7.003013,b:  1.987099\n",
      "Epoch (      1900/      5000) cost:  0.000022, W :  7.002510,b:  1.989253\n",
      "Epoch (      2000/      5000) cost:  0.000015, W :  7.002091,b:  1.991047\n",
      "Epoch (      2100/      5000) cost:  0.000011, W :  7.001742,b:  1.992541\n",
      "Epoch (      2200/      5000) cost:  0.000007, W :  7.001451,b:  1.993786\n",
      "Epoch (      2300/      5000) cost:  0.000005, W :  7.001209,b:  1.994824\n",
      "Epoch (      2400/      5000) cost:  0.000004, W :  7.001007,b:  1.995688\n",
      "Epoch (      2500/      5000) cost:  0.000002, W :  7.000839,b:  1.996408\n",
      "Epoch (      2600/      5000) cost:  0.000002, W :  7.000699,b:  1.997007\n",
      "Epoch (      2700/      5000) cost:  0.000001, W :  7.000582,b:  1.997507\n",
      "Epoch (      2800/      5000) cost:  0.000001, W :  7.000485,b:  1.997923\n",
      "Epoch (      2900/      5000) cost:  0.000001, W :  7.000404,b:  1.998270\n",
      "Epoch (      3000/      5000) cost:  0.000000, W :  7.000337,b:  1.998559\n",
      "Epoch (      3100/      5000) cost:  0.000000, W :  7.000280,b:  1.998799\n",
      "Epoch (      3200/      5000) cost:  0.000000, W :  7.000234,b:  1.999000\n",
      "Epoch (      3300/      5000) cost:  0.000000, W :  7.000195,b:  1.999167\n",
      "Epoch (      3400/      5000) cost:  0.000000, W :  7.000162,b:  1.999306\n",
      "Epoch (      3500/      5000) cost:  0.000000, W :  7.000135,b:  1.999422\n",
      "Epoch (      3600/      5000) cost:  0.000000, W :  7.000113,b:  1.999518\n",
      "Epoch (      3700/      5000) cost:  0.000000, W :  7.000094,b:  1.999599\n",
      "Epoch (      3800/      5000) cost:  0.000000, W :  7.000078,b:  1.999666\n",
      "Epoch (      3900/      5000) cost:  0.000000, W :  7.000065,b:  1.999721\n",
      "Epoch (      4000/      5000) cost:  0.000000, W :  7.000054,b:  1.999768\n",
      "Epoch (      4100/      5000) cost:  0.000000, W :  7.000045,b:  1.999807\n",
      "Epoch (      4200/      5000) cost:  0.000000, W :  7.000038,b:  1.999839\n",
      "Epoch (      4300/      5000) cost:  0.000000, W :  7.000031,b:  1.999866\n",
      "Epoch (      4400/      5000) cost:  0.000000, W :  7.000026,b:  1.999888\n",
      "Epoch (      4500/      5000) cost:  0.000000, W :  7.000022,b:  1.999907\n",
      "Epoch (      4600/      5000) cost:  0.000000, W :  7.000018,b:  1.999922\n",
      "Epoch (      4700/      5000) cost:  0.000000, W :  7.000015,b:  1.999935\n",
      "Epoch (      4800/      5000) cost:  0.000000, W :  7.000013,b:  1.999946\n",
      "Epoch (      4900/      5000) cost:  0.000000, W :  7.000010,b:  1.999955\n",
      "W:   7.000009\n",
      "b:   1.999963\n",
      "result : \n",
      "[ 8.99997131 15.99998006 22.9999888  29.99999754 37.00000628 44.00001503]\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    # 1. 예측을 먼저 한다.\n",
    "    y_predict = X * W + b\n",
    "    \n",
    "    # 2. 예측한 후에 얼마나 잘 예측했는지의 결과...Cost를 알수 있다.\n",
    "    cost = np.sum((y_predict -  Y) **2) / n_data # MSE 함수를 코드로 정의\n",
    "    \n",
    "    \n",
    "    # 3. 경사하강법 원리에 의해서 W, b 값을 조금씩 보정해 나간다.\n",
    "    W -= learning_rate * ((y_predict  -  Y) * X ).mean()\n",
    "    b -= learning_rate * (y_predict - Y).mean()\n",
    "    \n",
    "    if i % 100 ==0:\n",
    "        print('Epoch ({:10d}/{:10d}) cost:{:10f}, W :{:10f},b:{:10f}'.format(i, epochs,cost,W,b))\n",
    "print('W: {:10f}'.format(W))\n",
    "print('b: {:10f}'.format(b))\n",
    "print('result : ')\n",
    "print(X * W + b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
