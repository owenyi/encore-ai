{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from sklearn import datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKLearn Iris Data Loader and DataFrame Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                  5.1               3.5                1.4               0.2\n",
       "1                  4.9               3.0                1.4               0.2\n",
       "2                  4.7               3.2                1.3               0.2\n",
       "3                  4.6               3.1                1.5               0.2\n",
       "4                  5.0               3.6                1.4               0.2\n",
       "..                 ...               ...                ...               ...\n",
       "145                6.7               3.0                5.2               2.3\n",
       "146                6.3               2.5                5.0               1.9\n",
       "147                6.5               3.0                5.2               2.0\n",
       "148                6.2               3.4                5.4               2.3\n",
       "149                5.9               3.0                5.1               1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write Code !!\n",
    "iris = datasets.load_iris()\n",
    "iris\n",
    "\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X,y data Generator...Feature and Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "# 속성과 라벨을 X, y에 할당\n",
    "\n",
    "X, y = iris.data, iris.target\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training, Test 데이타를 8:2로 비율로 섞고, random_state=42로 지정\n",
    "    X_train, X_test, y_train, y_test 로 각각 할당된 값들을 torch 타입으로 변환 \n",
    "    torch.FloatTensor(), torch.LongTensor 사용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, \n",
    "                                                    iris.target, \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=iris.target)\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 하이퍼파라미터 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 4\n",
    "hidden_size = 56\n",
    "num_classes = 3\n",
    "num_epochs = 100\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuralNetwork  Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module): \n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    # 모델의 Forward Path를 정의\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "    \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuralNetwork  Model Excution , loss, optimizer, backward ..\n",
    "    Forward Propagation and Baward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1/100], Loss : 1.5722\n",
      "Epoch : [2/100], Loss : 1.1830\n",
      "Epoch : [3/100], Loss : 1.0737\n",
      "Epoch : [4/100], Loss : 1.0936\n",
      "Epoch : [5/100], Loss : 1.0391\n",
      "Epoch : [6/100], Loss : 0.9347\n",
      "Epoch : [7/100], Loss : 0.8400\n",
      "Epoch : [8/100], Loss : 0.7818\n",
      "Epoch : [9/100], Loss : 0.7544\n",
      "Epoch : [10/100], Loss : 0.7378\n",
      "Epoch : [11/100], Loss : 0.7129\n",
      "Epoch : [12/100], Loss : 0.6730\n",
      "Epoch : [13/100], Loss : 0.6256\n",
      "Epoch : [14/100], Loss : 0.5851\n",
      "Epoch : [15/100], Loss : 0.5605\n",
      "Epoch : [16/100], Loss : 0.5487\n",
      "Epoch : [17/100], Loss : 0.5386\n",
      "Epoch : [18/100], Loss : 0.5223\n",
      "Epoch : [19/100], Loss : 0.5006\n",
      "Epoch : [20/100], Loss : 0.4790\n",
      "Epoch : [21/100], Loss : 0.4630\n",
      "Epoch : [22/100], Loss : 0.4536\n",
      "Epoch : [23/100], Loss : 0.4465\n",
      "Epoch : [24/100], Loss : 0.4365\n",
      "Epoch : [25/100], Loss : 0.4228\n",
      "Epoch : [26/100], Loss : 0.4089\n",
      "Epoch : [27/100], Loss : 0.3989\n",
      "Epoch : [28/100], Loss : 0.3927\n",
      "Epoch : [29/100], Loss : 0.3870\n",
      "Epoch : [30/100], Loss : 0.3785\n",
      "Epoch : [31/100], Loss : 0.3676\n",
      "Epoch : [32/100], Loss : 0.3572\n",
      "Epoch : [33/100], Loss : 0.3496\n",
      "Epoch : [34/100], Loss : 0.3438\n",
      "Epoch : [35/100], Loss : 0.3372\n",
      "Epoch : [36/100], Loss : 0.3284\n",
      "Epoch : [37/100], Loss : 0.3192\n",
      "Epoch : [38/100], Loss : 0.3117\n",
      "Epoch : [39/100], Loss : 0.3057\n",
      "Epoch : [40/100], Loss : 0.2993\n",
      "Epoch : [41/100], Loss : 0.2915\n",
      "Epoch : [42/100], Loss : 0.2835\n",
      "Epoch : [43/100], Loss : 0.2766\n",
      "Epoch : [44/100], Loss : 0.2707\n",
      "Epoch : [45/100], Loss : 0.2643\n",
      "Epoch : [46/100], Loss : 0.2571\n",
      "Epoch : [47/100], Loss : 0.2502\n",
      "Epoch : [48/100], Loss : 0.2444\n",
      "Epoch : [49/100], Loss : 0.2389\n",
      "Epoch : [50/100], Loss : 0.2328\n",
      "Epoch : [51/100], Loss : 0.2265\n",
      "Epoch : [52/100], Loss : 0.2209\n",
      "Epoch : [53/100], Loss : 0.2158\n",
      "Epoch : [54/100], Loss : 0.2106\n",
      "Epoch : [55/100], Loss : 0.2050\n",
      "Epoch : [56/100], Loss : 0.2000\n",
      "Epoch : [57/100], Loss : 0.1954\n",
      "Epoch : [58/100], Loss : 0.1908\n",
      "Epoch : [59/100], Loss : 0.1860\n",
      "Epoch : [60/100], Loss : 0.1816\n",
      "Epoch : [61/100], Loss : 0.1776\n",
      "Epoch : [62/100], Loss : 0.1736\n",
      "Epoch : [63/100], Loss : 0.1695\n",
      "Epoch : [64/100], Loss : 0.1657\n",
      "Epoch : [65/100], Loss : 0.1622\n",
      "Epoch : [66/100], Loss : 0.1587\n",
      "Epoch : [67/100], Loss : 0.1553\n",
      "Epoch : [68/100], Loss : 0.1520\n",
      "Epoch : [69/100], Loss : 0.1490\n",
      "Epoch : [70/100], Loss : 0.1460\n",
      "Epoch : [71/100], Loss : 0.1431\n",
      "Epoch : [72/100], Loss : 0.1403\n",
      "Epoch : [73/100], Loss : 0.1378\n",
      "Epoch : [74/100], Loss : 0.1352\n",
      "Epoch : [75/100], Loss : 0.1327\n",
      "Epoch : [76/100], Loss : 0.1304\n",
      "Epoch : [77/100], Loss : 0.1281\n",
      "Epoch : [78/100], Loss : 0.1259\n",
      "Epoch : [79/100], Loss : 0.1238\n",
      "Epoch : [80/100], Loss : 0.1218\n",
      "Epoch : [81/100], Loss : 0.1199\n",
      "Epoch : [82/100], Loss : 0.1180\n",
      "Epoch : [83/100], Loss : 0.1162\n",
      "Epoch : [84/100], Loss : 0.1145\n",
      "Epoch : [85/100], Loss : 0.1129\n",
      "Epoch : [86/100], Loss : 0.1113\n",
      "Epoch : [87/100], Loss : 0.1098\n",
      "Epoch : [88/100], Loss : 0.1083\n",
      "Epoch : [89/100], Loss : 0.1069\n",
      "Epoch : [90/100], Loss : 0.1055\n",
      "Epoch : [91/100], Loss : 0.1042\n",
      "Epoch : [92/100], Loss : 0.1029\n",
      "Epoch : [93/100], Loss : 0.1017\n",
      "Epoch : [94/100], Loss : 0.1005\n",
      "Epoch : [95/100], Loss : 0.0994\n",
      "Epoch : [96/100], Loss : 0.0983\n",
      "Epoch : [97/100], Loss : 0.0972\n",
      "Epoch : [98/100], Loss : 0.0962\n",
      "Epoch : [99/100], Loss : 0.0952\n",
      "Epoch : [100/100], Loss : 0.0943\n"
     ]
    }
   ],
   "source": [
    "# 위에서 정의한 클래스를 인스턴스화 시킴\n",
    "# model = NeuralNet(input_size, hidden_size, num_classes).to(device) # to(device) : 이 모델을 gpu 서버에서 돌린다는 뜻\n",
    "model = NeuralNet(input_size, hidden_size, num_classes)\n",
    "# loss, optimizer를 선정의\n",
    "loss_function = nn.CrossEntropyLoss() # Loss 기능 안에 Softmax 함수 기능 포함되어져 있다.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(num_epochs): # 5번\n",
    "    # Forward Pass\n",
    "    pred = model(X_train)\n",
    "    loss = loss_function(pred, y_train)\n",
    "    \n",
    "    loss_list.append(loss.item())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch : [{epoch + 1}/{num_epochs}], Loss : {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  학습을 마친 최종적인 모델의 값을 저장. model.ckpt 파일로 저장합니다.\n",
    "# torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch(학습)에 따른 Loss감소를 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(num_epochs), loss_list)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습을 통해서 Loss를 감소시켰다면 이제는Test를 해봅니다.\n",
    "    테스트 할때는 학습의 의미가 없기때문에 Gradient Descent를 사용하지 않도록 합니다.\n",
    "    그 결과로 컴퓨터 Performance를 높이는 결과를 가져옵니다.\n",
    "    이때 우리가 테스트하는 데이타는 이미지가 아니고 단순 숫자 값으로 입력된다는 점을 잘 고려해야합니다.\n",
    "    출력된 값 중에서 가장 높은 값의 인덱스가 바로 target의 라벨이 됩니다.\n",
    "    \n",
    "    예측한 값과 정답을 일일이 비교해서 출력하고\n",
    "    총 30개의 Test 데이타 중에서 정확하게 맞춘 갯수를 최종적으로 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Network on the Test Images : 100.0%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # 미분 안하겠다...실제로 학습할 필요가 없을 때 이 구문을 반드시 작성\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for features, labels in zip(X_test, y_test):\n",
    "        outputs = model(features)\n",
    "        \n",
    "        total += 1\n",
    "        correct += (torch.argmax(outputs) == labels).sum().item()\n",
    "\n",
    "    print(f\"Accuracy of the Network on the Test Images : {100*correct/total}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
